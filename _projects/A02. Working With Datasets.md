---
layout: page
title: A02. Working With Datasets
description: Data is central to machine learning.  This tutorial introduces the `Dataset` class that DeepChem uses to store and manage data.  It provides simple but powerful tools for efficiently working with large amounts of data.  It also is designed to easily interact with other popular Python frameworks such as NumPy, Pandas, TensorFlow, and PyTorch.
img: assets/img/1.jpg
importance: 1
category: Bioinformatics
---

---

```python
!pip install --pre deepchem
```

---

We can now import the `deepchem` package to play with.

---

```python
import deepchem as dc
dc.__version__
```

---

# Anatomy of a Dataset

In the last tutorial we loaded the Delaney dataset of molecular solubilities.  Let's load it again.

---

```python
tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')
train_dataset, valid_dataset, test_dataset = datasets
```

---

We now have three Dataset objects: the training, validation, and test sets.  What information does each of them contain?  We can start to get an idea by printing out the string representation of one of them.

---

```python
print(test_dataset)
```

---

<DiskDataset X.shape: (113,), y.shape: (113, 1), w.shape: (113, 1), ids: ['c1cc2ccc3cccc4ccc(c1)c2c34' 'Cc1cc(=O)[nH]c(=S)[nH]1'
 'Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 ' ...
 'c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43' 'Cc1occc1C(=O)Nc2ccccc2'
 'OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O '], task_names: ['measured log solubility in mols per litre']>

---

There's a lot of information there, so let's start at the beginning.  It begins with the label "DiskDataset".  Dataset is an abstract class.  It has a few subclasses that correspond to different ways of storing data.

- `DiskDataset` is a dataset that has been saved to disk.  The data is stored in a way that can be efficiently accessed, even if the total amount of data is far larger than your computer's memory.
- `NumpyDataset` is an in-memory dataset that holds all the data in NumPy arrays.  It is a useful tool when manipulating small to medium sized datasets that can fit entirely in memory.
- `ImageDataset` is a more specialized class that stores some or all of the data in image files on disk.  It is useful when working with models that have images as their inputs or outputs.

Now let's consider the contents of the Dataset.  Every Dataset stores a list of *samples*.  Very roughly speaking, a sample is a single data point.  In this case, each sample is a molecule.  In other datasets a sample might correspond to an experimental assay, a cell line, an image, or many other things.  For every sample the dataset stores the following information.

- The *features*, referred to as `X`.  This is the input that should be fed into a model to represent the sample.
- The *labels*, referred to as `y`.  This is the desired output from the model.  During training, it tries to make the model's output for each sample as close as possible to `y`.
- The *weights*, referred to as `w`.  This can be used to indicate that some data values are more important than others.  In later tutorials we will see examples of how this is useful.
- An *ID*, which is a unique identifier for the sample.  This can be anything as long as it is unique.  Sometimes it is just an integer index, but in this dataset the ID is a SMILES string describing the molecule.

Notice that `X`, `y`, and `w` all have 113 as the size of their first dimension.  That means this dataset contains 113 samples.

The final piece of information listed in the output is `task_names`.  Some datasets contain multiple pieces of information for each sample.  For example, if a sample represents a molecule, the dataset might record the results of several different experiments on that molecule.  This dataset has only a single task: "measured log solubility in mols per litre".  Also notice that `y` and `w` each have shape (113, 1).  The second dimension of these arrays usually matches the number of tasks.

# Accessing Data from a Dataset

There are many ways to access the data contained in a dataset.  The simplest is just to directly access the `X`, `y`, `w`, and `ids` properties.  Each of these returns the corresponding information as a NumPy array.

---

```python
test_dataset.y
```

---

array([[-1.60114461],
       [ 0.20848251],
       [-0.01602738],
       [-2.82191713],
       [-0.52891635],
       [ 1.10168349],
       [-0.88987406],
       [-0.52649706],
       [-0.76358725],
       [-0.64020358],
       [-0.38569452],
       [-0.62568785],
       [-0.39585553],
       [-2.05306753],
       [-0.29666474],
       [-0.73213651],
        ...
       [-0.30827732],
       [-1.95145746],
       [-0.83568202],
       [ 0.10977558],
       [ 1.90488697],
       [-0.75149081],
       [-1.65630437],
       [ 0.74362893],
       [-2.42079925],
       [-0.20957039],
       [ 1.01458914]])

---

This is a very easy way to access data, but you should be very careful about using it.  This requires the data for all samples to be loaded into memory at once.  That's fine for small datasets like this one, but for large datasets it could easily take more memory than you have.

A better approach is to iterate over the dataset.  That lets it load just a little data at a time, process it, then free the memory before loading the next bit.  You can use the `itersamples()` method to iterate over samples one at a time.

---

```python
test_dataset.y
```

---

[-1.60114461] c1cc2ccc3cccc4ccc(c1)c2c34
[0.20848251] Cc1cc(=O)[nH]c(=S)[nH]1
[-0.01602738] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 
[-2.82191713] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45
[-0.52891635] C1=Cc2cccc3cccc1c23
[1.10168349] CC1CO1
[-0.88987406] CCN2c1ccccc1N(C)C(=S)c3cccnc23 
[-0.52649706] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O
[-0.76358725] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F
[-0.64020358] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl 
[-0.38569452] COc2c1occc1cc3ccc(=O)oc23 
[-0.62568785] CN2C(=C(O)c1ccccc1S2(=O)=O)C(=O)Nc3ccccn3 
[-0.39585553] Cc3cc2nc1c(=O)[nH]c(=O)nc1n(CC(O)C(O)C(O)CO)c2cc3C
[-2.05306753] c1ccc(cc1)c2ccc(cc2)c3ccccc3
[-0.29666474] CC34CC(=O)C1C(CCC2=CC(=O)CCC12C)C3CCC4(=O) 
[-0.73213651] c1ccc2c(c1)sc3ccccc23
[-1.27744393] CC23Cc1cnoc1C=C2CCC4C3CCC5(C)C4CCC5(O)C#C
[0.0081655] OC(C(=O)c1ccccc1)c2ccccc2
[0.97588054] OCC2OC(Oc1ccccc1CO)C(O)C(O)C2O
[-0.10796031] CC3C2CCC1(C)C=CC(=O)C(=C1C2OC3=O)C
[0.59847167] O=Cc2ccc1OCOc1c2 
[-0.60149498] CC1CCCCC1NC(=O)Nc2ccccc2
[-0.34988907] CC(=O)N(S(=O)c1ccc(N)cc1)c2onc(C)c2C 
[0.34686576] C1N(C(=O)NCC(C)C)C(=O)NC1
[0.62750312] CNC(=O)Oc1ccccc1C2OCCO2
[0.14848418] CC1=C(CCCO1)C(=O)Nc2ccccc2 
[0.02268122] Cn2c(=O)on(c1ccc(Cl)c(Cl)c1)c2=O
[-0.85310089] C1Cc2cccc3cccc1c23
[-2.72079091] c1ccc2cc3c4cccc5cccc(c3cc2c1)c45
[0.42476682] Nc1cc(nc(N)n1=O)N2CCCCC2 
[0.01300407] O=c2c(C3CCCc4ccccc43)c(O)c1ccccc1o2 
[-2.4851523] CC(C)C(Nc1ccc(cc1Cl)C(F)(F)F)C(=O)OC(C#N)c2cccc(Oc3ccccc3)c2
[-2.15516147] Cc1c(F)c(F)c(COC(=O)C2C(C=C(Cl)C(F)(F)F)C2(C)C)c(F)c1F
[1.00975056] c2ccc1[nH]nnc1c2
[0.82588471] c2ccc1ocnc1c2
[-0.90390593] CCOC(=O)c1cncn1C(C)c2ccccc2
[-0.91067993] CCN2c1ccccc1N(C)C(=O)c3ccccc23 
[-0.82455329] OCC(O)COC(=O)c1ccccc1Nc2ccnc3cc(Cl)ccc23
[1.26909819] OCC1OC(OC2C(O)C(O)C(O)OC2CO)C(O)C(O)C1O
[-1.14825397] CC34CCc1c(ccc2cc(O)ccc12)C3CCC4=O
[-2.1343556] ClC1=C(Cl)C(Cl)(C(=C1Cl)Cl)C2(Cl)C(=C(Cl)C(=C2Cl)Cl)Cl
[-1.15744727] ClC1(C(=O)C2(Cl)C3(Cl)C14Cl)C5(Cl)C2(Cl)C3(Cl)C(Cl)(Cl)C45Cl
[-0.1045733] Oc1ccc(c(O)c1)c3oc2cc(O)cc(O)c2c(=O)c3O 
[0.53073162] C1SC(=S)NC1(=O)
[-1.22567118] ClC(Cl)C(Cl)(Cl)SN2C(=O)C1CC=CCC1C2=O 
[-1.66452995] ClC1=C(Cl)C2(Cl)C3C4CC(C=C4)C3C1(Cl)C2(Cl)Cl
[0.24525568] CC(=O)Nc1nnc(s1)S(N)(=O)=O 
[-0.13215318] CC1=C(SCCO1)C(=O)Nc2ccccc2
[-0.97067826] CN(C(=O)COc1nc2ccccc2s1)c3ccccc3
[-0.23376326] CN(C(=O)NC(C)(C)c1ccccc1)c2ccccc2
[1.21297072] Nc1nccs1 
[-1.2595412] CN(C=Nc1ccc(C)cc1C)C=Nc2ccc(C)cc2C
[0.49686159] OCC(O)C2OC1OC(OC1C2O)C(Cl)(Cl)Cl 
[0.22396595] Nc3nc(N)c2nc(c1ccccc1)c(N)nc2n3
[-0.44182199] CC2Nc1cc(Cl)c(cc1C(=O)N2c3ccccc3C)S(N)(=O)=O 
[0.47895886] CN1CC(O)N(C1=O)c2nnc(s2)C(C)(C)C
[0.08267956] CCC1(C(=O)NC(=O)NC1=O)C2=CCC3CCC2C3
[-1.51840498] CCC(C)C(=O)OC2CC(C)C=C3C=CC(C)C(CCC1CC(O)CC(=O)O1)C23 
[-0.34795364] CC2Cc1ccccc1N2NC(=O)c3ccc(Cl)c(c3)S(N)(=O)=O 
[-0.83858516] o1c2ccccc2c3ccccc13
[-0.13699176] O=C(Nc1ccccc1)Nc2ccccc2
[-2.59498796] c1ccc2c(c1)c3cccc4c3c2cc5ccccc54
[0.13106531] COc1ccc(cc1)C(O)(C2CC2)c3cncnc3 
[0.09042128] c1cnc2c(c1)ccc3ncccc23
[1.18877785] OCC1OC(CO)(OC2OC(COC3OC(CO)C(O)C(O)C3O)C(O)C(O)C2O)C(O)C1O
[-0.82697258] CCOC(=O)c1ccccc1S(=O)(=O)NN(C=O)c2nc(Cl)cc(OC)n2
[-1.16857599] CC34CCC1C(=CCc2cc(O)ccc12)C3CCC4=O
[0.37589721] CN(C)C(=O)Oc1cc(C)nn1c2ccccc2
[-0.24344041] OC(Cn1cncn1)(c2ccc(F)cc2)c3ccccc3F
[-2.00952036] Cc1c2ccccc2c(C)c3ccc4ccccc4c13
[-0.59181783] Cc3nnc4CN=C(c1ccccc1Cl)c2cc(Cl)ccc2n34
[-0.15634606] Cc3ccnc4N(C1CC1)c2ncccc2C(=O)Nc34 
[-2.87272217] c1cc2cccc3c4cccc5cccc(c(c1)c23)c54
[-0.34069577] COc1cc(cc(OC)c1O)C6C2C(COC2=O)C(OC4OC3COC(C)OC3C(O)C4O)c7cc5OCOc5cc67
[0.27622256] O=c1[nH]cnc2nc[nH]c12 
[-2.15467761] C1C(O)CCC2(C)CC3CCC4(C)C5(C)CC6OCC(C)CC6OC5CC4C3C=C21
[-0.02812382] Cc1ccccc1n3c(C)nc2ccccc2c3=O
[-2.77401524] CCOc1ccc(cc1)C(C)(C)COCc3cccc(Oc2ccccc2)c3
[0.25638441] CCC1(CCC(=O)NC1=O)c2ccccc2 
[0.84040043] CC1CC(C)C(=O)C(C1)C(O)CC2CC(=O)NC(=O)C2 
[-0.86277804] CC(=O)C3CCC4C2CC=C1CC(O)CCC1(C)C2CCC34C 
[-1.52082426] Cc1ccc(OP(=O)(Oc2cccc(C)c2)Oc3ccccc3C)cc1
[0.29702844] CSc1nnc(c(=O)n1N)C(C)(C)C
[0.44363727] Nc1ncnc2n(ccc12)C3OC(CO)C(O)C3O 
[0.47460415] O=C2NC(=O)C1(CC1)C(=O)N2 
[-0.08376743] C1Cc2ccccc2C1
[0.68556602] c1ccc2cnccc2c1
[0.79201468] OCC1OC(C(O)C1O)n2cnc3c(O)ncnc23
[-1.2401869] c2(Cl)c(Cl)c(Cl)c1nccnc1c2(Cl) 
[0.6129874] C1OC1c2ccccc2 
[-0.58214068] CCC(=C(CC)c1ccc(O)cc1)c2ccc(O)cc2 
[-1.51598569] c1ccc2c(c1)c3cccc4cccc2c34
[-1.93984487] CC(C)C(C(=O)OC(C#N)c1cccc(Oc2ccccc2)c1)c3ccc(OC(F)F)cc3
[-0.30295489] CCCC1COC(Cn2cncn2)(O1)c3ccc(Cl)cc3Cl
[-0.24827899] O=C2CN(N=Cc1ccc(o1)N(=O)=O)C(=O)N2 
[1.06442646] NC(=O)c1cnccn1
[-1.48259952] OC4=C(C1CCC(CC1)c2ccc(Cl)cc2)C(=O)c3ccccc3C4=O
[0.0275198] O=C(Cn1ccnc1N(=O)=O)NCc2ccccc2
[0.33718861] CCC1(C(=O)NC(=O)NC1=O)C2=CCCCC2 
[-0.91600236] COC(=O)C1=C(C)NC(=C(C1c2ccccc2N(=O)=O)C(=O)OC)C 
[0.58637523] O=C2NC(=O)C1(CCC1)C(=O)N2
[-0.62084928] CCCOP(=S)(OCCC)SCC(=O)N1CCCCC1C
[-0.30827732] N(c1ccccc1)c2ccccc2
[-1.95145746] ClC(Cl)=C(c1ccc(Cl)cc1)c2ccc(Cl)cc2
[-0.83568202] O=c2[nH]c1CCCc1c(=O)n2C3CCCCC3
[0.10977558] CCC1(C(=O)NCNC1=O)c2ccccc2
[1.90488697] O=C1CCCN1
[-0.75149081] COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C 
[-1.65630437] ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl
[0.74362893] c1ccsc1
[-2.42079925] c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43
[-0.20957039] Cc1occc1C(=O)Nc2ccccc2
[1.01458914] OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O

---

```python
for X, y, w, ids in test_dataset.iterbatches(batch_size=50):
    print(y.shape)
```

---

(50, 1)
(50, 1)
(13, 1)

---

`iterbatches()` has other features that are useful when training models.  For example, `iterbatches(batch_size=100, epochs=10, deterministic=False)` will iterate over the complete dataset ten times, each time with the samples in a different random order.

Datasets can also expose data using the standard interfaces for TensorFlow and PyTorch.  To get a `tensorflow.data.Dataset`, call `make_tf_dataset()`.  To get a `torch.utils.data.IterableDataset`, call `make_pytorch_dataset()`.  See the API documentation for more details.

The final way of accessing data is `to_dataframe()`.  This copies the data into a Pandas `DataFrame`.  This requires storing all the data in memory at once, so you should only use it with small datasets.

---

```python
test_dataset.to_dataframe()
```

---

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X</th>
      <th>y</th>
      <th>w</th>
      <th>ids</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-1.601145</td>
      <td>1.0</td>
      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>0.208483</td>
      <td>1.0</td>
      <td>Cc1cc(=O)[nH]c(=S)[nH]1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-0.016027</td>
      <td>1.0</td>
      <td>Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-2.821917</td>
      <td>1.0</td>
      <td>c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45</td>
    </tr>
    <tr>
      <th>4</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-0.528916</td>
      <td>1.0</td>
      <td>C1=Cc2cccc3cccc1c23</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>108</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-1.656304</td>
      <td>1.0</td>
      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>
    </tr>
    <tr>
      <th>109</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>0.743629</td>
      <td>1.0</td>
      <td>c1ccsc1</td>
    </tr>
    <tr>
      <th>110</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-2.420799</td>
      <td>1.0</td>
      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>
    </tr>
    <tr>
      <th>111</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>-0.209570</td>
      <td>1.0</td>
      <td>Cc1occc1C(=O)Nc2ccccc2</td>
    </tr>
    <tr>
      <th>112</th>
      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>
      <td>1.014589</td>
      <td>1.0</td>
      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>
    </tr>
  </tbody>
</table>
<p>113 rows × 4 columns</p>
</div>

---

# Creating Datasets

Now let's talk about how you can create your own datasets.  Creating a `NumpyDataset` is very simple: just pass the arrays containing the data to the constructor.  Let's create some random arrays, then wrap them in a NumpyDataset.

---

```python
import numpy as np

X = np.random.random((10, 5))
y = np.random.random((10, 2))
dataset = dc.data.NumpyDataset(X=X, y=y)
print(dataset)
```

---

<NumpyDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>

---

Notice that we did not specify weights or IDs.  These are optional, as is `y` for that matter.  Only `X` is required.  Since we left them out, it automatically built `w` and `ids` arrays for us, setting all weights to 1 and setting the IDs to integer indices.

---

```python
dataset.to_dataframe()
```

---

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>y1</th>
      <th>y2</th>
      <th>w</th>
      <th>ids</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.863055</td>
      <td>0.098521</td>
      <td>0.142146</td>
      <td>0.414407</td>
      <td>0.122060</td>
      <td>0.233247</td>
      <td>0.360629</td>
      <td>1.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.365426</td>
      <td>0.559426</td>
      <td>0.098727</td>
      <td>0.325001</td>
      <td>0.434306</td>
      <td>0.378986</td>
      <td>0.675236</td>
      <td>1.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.544838</td>
      <td>0.141913</td>
      <td>0.396298</td>
      <td>0.420153</td>
      <td>0.570306</td>
      <td>0.372066</td>
      <td>0.989235</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.781480</td>
      <td>0.694588</td>
      <td>0.382052</td>
      <td>0.657474</td>
      <td>0.866507</td>
      <td>0.228217</td>
      <td>0.755437</td>
      <td>1.0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.932375</td>
      <td>0.357985</td>
      <td>0.898869</td>
      <td>0.121361</td>
      <td>0.686195</td>
      <td>0.838544</td>
      <td>0.559271</td>
      <td>1.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.165614</td>
      <td>0.320273</td>
      <td>0.422490</td>
      <td>0.404307</td>
      <td>0.502295</td>
      <td>0.920853</td>
      <td>0.063027</td>
      <td>1.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.574826</td>
      <td>0.464535</td>
      <td>0.468637</td>
      <td>0.261444</td>
      <td>0.957813</td>
      <td>0.852140</td>
      <td>0.057540</td>
      <td>1.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.623051</td>
      <td>0.542162</td>
      <td>0.622751</td>
      <td>0.519985</td>
      <td>0.634665</td>
      <td>0.370191</td>
      <td>0.824125</td>
      <td>1.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.633993</td>
      <td>0.583943</td>
      <td>0.404875</td>
      <td>0.458489</td>
      <td>0.959906</td>
      <td>0.591928</td>
      <td>0.861326</td>
      <td>1.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.052331</td>
      <td>0.246525</td>
      <td>0.582329</td>
      <td>0.752230</td>
      <td>0.584350</td>
      <td>0.180186</td>
      <td>0.959682</td>
      <td>1.0</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div>

What about creating a DiskDataset?  If you have the data in NumPy arrays, you can call `DiskDataset.from_numpy()` to save it to disk.  Since this is just a tutorial, we will save it to a temporary directory.

---

```python
import tempfile

with tempfile.TemporaryDirectory() as data_dir:
    disk_dataset = dc.data.DiskDataset.from_numpy(X=X, y=y, data_dir=data_dir)
    print(disk_dataset)
```

---

<DiskDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>

---

What about larger datasets that can't fit in memory?  What if you have some huge files on disk containing data on hundreds of millions of molecules?  The process for creating a DiskDataset from them is slightly more involved.  Fortunately, DeepChem's `DataLoader` framework can automate most of the work for you.  That is a larger subject, so we will return to it in a later tutorial.

---

# Congratulations! Time to join the Community!

Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:

---

## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)

This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.

---

## Join the DeepChem Gitter

The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!
