---
layout: page
title: ML08. Student Performance Dataset Solution
description: This dataset contains comprehensive information on 2,392 high school students, detailing their demographics, study habits, parental involvement, extracurricular activities, and academic performance. The target variable, GradeClass, classifies students' grades into distinct categories, providing a robust dataset for educational research, predictive modeling, and statistical analysis.
img: assets/img/1.jpg
importance: 1
category: work
---

## **Setup**

- This section describes activities required before you can access any Azure ML services functionality.

### **Azure Subscription**

- In order to create an Azure ML Workspace, first you need access to an Azure subscription.  An Azure subscription allows you to manage storage, compute, and other assets in the Azure cloud.  You can [create a new subscription](https://azure.microsoft.com/en-us/free/) or access existing subscription information from the [Azure portal](https://portal.azure.com).  Later in this notebook you will need information such as your subscription ID in order to create and access AML workspaces.

---

### **Azure ML SDK and other library installation**

If you are running in your own environment, follow [SDK installation instructions](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-environment).  If you are running in Azure Notebooks or another Microsoft managed environment, the SDK is already installed.

Also install following libraries to your environment. Many of the example notebooks depend on them

```
(myenv) $ conda install -y matplotlib tqdm scikit-learn
```

Once installation is complete, the following cell checks the Azure ML SDK version:

If you are running in your own environment, follow [SDK installation instructions](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-environment).  If you are running in Azure Notebooks or another Microsoft managed environment, the SDK is already installed.

Also install following libraries to your environment. Many of the example notebooks depend on them

```
(myenv) $ conda install -y matplotlib tqdm scikit-learn
```

Once installation is complete, the following cell checks the Azure ML SDK version:

---

```python
import azureml.core

print("This notebook was created using version 1.56.0 of the Azure ML SDK")
print("You are currently using version", azureml.core.VERSION, "of the Azure ML SDK")
```

- If you are using an older version of the SDK then this notebook was created using, you should upgrade your SDK.

---

## **Configure your Azure ML workspace**

### **Workspace parameters**

- To use an AML Workspace, you will need to import the Azure ML SDK and supply the following information:

  - Your subscription id

  - A resource group name

  - (optional) The region that will host your workspace

  - A name for your workspace

- You can get your subscription ID from the [Azure portal](https://portal.azure.com).

- You will also need access to a [_resource group_](https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-overview#resource-groups), which organizes Azure resources and provides a default region for the resources in a group.  You can see what resource groups to which you have access, or create a new one in the [Azure portal](https://portal.azure.com).  If you don't have a resource group, the create workspace command will create one for you using the name you provide.

- The region to host your workspace will be used if you are creating a new workspace.  You do not need to specify this if you are using an existing workspace. You can find the list of supported regions [here](https://azure.microsoft.com/en-us/global-infrastructure/services/?products=machine-learning-service).  You should pick a region that is close to your location or that contains your data.

- The name for your workspace is unique within the subscription and should be descriptive enough to discern among other AML Workspaces.  The subscription may be used only by you, or it may be used by your department or your entire enterprise, so choose a name that makes sense for your situation.

- The following cell allows you to specify your workspace parameters.  This cell uses the python method `os.getenv` to read values from environment variables which is useful for automation.  If no environment variable exists, the parameters will be set to the specified default values.

- If you ran the Azure Machine Learning [quickstart](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started) in Azure Notebooks, you already have a configured workspace!  You can go to your Azure Machine Learning Getting Started library, view *config.json* file, and copy-paste the values for subscription ID, resource group and workspace name below.

Replace the default values in the cell below with your workspace parameters

---

```python
import os

subscription_id = os.getenv("SUBSCRIPTION_ID", default="88****83-****-4f6a-****-43f185****e1")
resource_group = os.getenv("RESOURCE_GROUP", default="RG006-StudentPerfomance")
workspace_name = os.getenv("WORKSPACE_NAME", default="WS006-StudentPerfomance")
workspace_region = os.getenv("WORKSPACE_REGION", default="South Africa North")
```

---

### **Access your workspace**

- The following cell uses the Azure ML SDK to attempt to load the workspace specified by your parameters.  If this cell succeeds, your notebook library will be configured to access the workspace from all notebooks using the `Workspace.from_config()` method.  The cell can fail if the specified workspace doesn't exist or you don't have permissions to access it.

---

```python
from azureml.core import Workspace

try:
    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)
    # write the details of the workspace to a configuration file to the notebook library
    ws.write_config()
    print("Workspace configuration succeeded. Skip the workspace creation steps below")
except:
    print("Workspace not accessible. Change your parameters or create a new workspace below")
```

> Workspace configuration succeeded. Skip the workspace creation steps below

---

### **Create compute resources for your training experiments**

- Many of the sample notebooks use Azure ML managed compute (AmlCompute) to train models using a dynamically scalable pool of compute. In this section you will create default compute clusters for use by the other notebooks and any other operations you choose.

> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.

- To create a cluster, you need to specify a compute configuration that specifies the type of machine to be used and the scalability behaviors.  Then you choose a name for the cluster that is unique within the workspace that can be used to address the cluster later.

The cluster parameters are:

- **vm_size** - this describes the virtual machine type and size used in the cluster.  All machines in the cluster are the same type.  You can get the list of vm sizes available in your region by using the CLI command

```shell
az vm list-skus -o tsv
```

- **Min_nodes** - this sets the minimum size of the cluster.  If you set the minimum to 0 the cluster will shut down all nodes while not in use.  Setting this number to a value higher than 0 will allow for faster start-up times, but you will also be billed when the cluster is not in use.

- **Max_nodes** - this sets the maximum size of the cluster.  Setting this to a larger number allows for more concurrency and a greater distributed processing of scale-out jobs.

- To create a **CPU** cluster now, run the cell below. The autoscale settings mean that the cluster will scale down to 0 nodes when inactive and up to 4 nodes when busy.

---

```shell
from azureml.core.compute import ComputeTarget, AmlCompute
from azureml.core.compute_target import ComputeTargetException

# Choose a name for your CPU cluster
cpu_cluster_name = "cpu-cluster"

# Verify that cluster does not exist already
try:
    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)
    print("Found existing cpu-cluster")
except ComputeTargetException:
    print("Creating new cpu-cluster")
    
    # Specify the configuration for the new cluster
    compute_config = AmlCompute.provisioning_configuration(vm_size="STANDARD_D2_V2",
                                                        min_nodes=0,
                                                        max_nodes=4)

    # Create the cluster with the specified name and configuration
    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)
    
    # Wait for the cluster to complete, show the output log
    cpu_cluster.wait_for_completion(show_output=True)
```

> Creating new cpu-cluster
> InProgress......
> SucceededProvisioning operation finished, operation "Succeeded"
> Succeeded
> AmlCompute wait for completion finished
> Minimum number of nodes requested have been provisioned

---

## **Table of Contents**

1. Student Information
    - Student ID
    - Demographic Details
    - Study Habits

2. Parental Involvement

3. Extracurricular Activities

4. Academic Performance

5. Target Variable: Grade Class

---

## **Student Information**

### **Student ID**

- StudentID: A unique identifier assigned to each student (1001 to 3392).

### **Demographic Details**

- Age: The age of the students ranges from 15 to 18 years.

- Gender: Gender of the students, where 0 represents Male and 1 represents Female.

- Ethnicity: The ethnicity of the students, coded as follows:
  - 0: Caucasian

  - 1: African American

  - 2: Asian

  - 3: Other

- ParentalEducation: The education level of the parents, coded as follows:
  - 0: None

  - 1: High School

  - 2: Some College

  - 3: Bachelor's
  
  - 4: Higher

---

### **Extracurricular Activities**

- Extracurricular: Participation in extracurricular activities, where 0 indicates No and 1 indicates Yes.

- Sports: Participation in sports, where 0 indicates No and 1 indicates Yes.

- Music: Participation in music activities, where 0 indicates No and 1 indicates Yes.

- Volunteering: Participation in volunteering, where 0 indicates No and 1 indicates Yes.

---

### **Academic Performance**

- GPA: Grade Point Average on a scale from 2.0 to 4.0, influenced by study habits, parental involvement, and extracurricular activities.

---

### **Target Variable: Grade Class**

- GradeClass: Classification of students' grades based on GPA:
  - 0: 'A' (GPA >= 3.5)
  
  - 1: 'B' (3.0 <= GPA < 3.5)

  - 2: 'C' (2.5 <= GPA < 3.0)

  - 3: 'D' (2.0 <= GPA < 2.5)

  - 4: 'F' (GPA < 2.0)

---

### **Conclusion**

- This dataset offers a comprehensive view of the factors influencing students' academic performance, making it ideal for educational research, development of predictive models, and statistical analysis.

---

## **Laod Data**

```python
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
import seaborn as sns 

import os 
for dirname, _, filenames in os.walk('Student_performance_data _.csv'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
# To ignore warinings
import warnings
warnings.filterwarnings('ignore')

```

---

### NumPy

- Short for Numerical Python, is a fundamental library in Python used for scientific computing and data manipulation. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays efficiently.

### Key Features of NumPy

- Array Objects: Central to NumPy is the ndarray (n-dimensional array) object, which is a grid of values of the same type, indexed by a tuple of non-negative integers.

- Mathematical Functions: NumPy includes a wide array of mathematical operations such as trigonometric, statistical, and algebraic functions.

- Broadcasting: This feature allows arithmetic operations to be performed on arrays of different shapes, making it easier to write code without explicitly handling the shape of the data.

- Vectorization: NumPy operations are optimized to run efficiently, allowing for element-wise operations on arrays without the need for explicit loops.

- Integration with Other Libraries: NumPy serves as the foundation for many other scientific computing libraries in Python, such as SciPy, pandas, and Matplotlib.

### Explanation

- Import os: Import the os module to interact with the operating system.

- os.walk(): This function generates the file names in a directory tree by walking either top-down or bottom-up.

- dirname: The current directory path.

- _: A placeholder for directory names, which we don't use in this case.

- filenames: A list of the file names in the current directory.

- os.path.join(): This function joins one or more path components intelligently.

---

```python
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
import seaborn as sns 

import os 
for dirname, _, filenames in os.walk('Student_performance_data _.csv'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
# To ignore warinings
import warnings
warnings.filterwarnings('ignore')

```

---

### NumPy

- Short for Numerical Python, is a fundamental library in Python used for scientific computing and data manipulation. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays efficiently.

### Key Features of NumPy

- Array Objects: Central to NumPy is the ndarray (n-dimensional array) object, which is a grid of values of the same type, indexed by a tuple of non-negative integers.

- Mathematical Functions: NumPy includes a wide array of mathematical operations such as trigonometric, statistical, and algebraic functions.

- Broadcasting: This feature allows arithmetic operations to be performed on arrays of different shapes, making it easier to write code without explicitly handling the shape of the data.

- Vectorization: NumPy operations are optimized to run efficiently, allowing for element-wise operations on arrays without the need for explicit loops.

- Integration with Other Libraries: NumPy serves as the foundation for many other scientific computing libraries in Python, such as SciPy, pandas, and Matplotlib.

### Explanation

- Import os: Import the os module to interact with the operating system.

- os.walk(): This function generates the file names in a directory tree by walking either top-down or bottom-up.

- dirname: The current directory path.

- _: A placeholder for directory names, which we don't use in this case.

- filenames: A list of the file names in the current directory.

- os.path.join(): This function joins one or more path components intelligently.

---

```python
# Load Data from csv
df = pd.read_csv('Student_performance_data _.csv')

# Watch how our data looks like
df.head()

```

---



- The df.head() function is used to display the first few rows of a DataFrame in pandas. By default, it shows the first 5 rows, but you can specify a different number of rows as an argument if needed.

## Prepare Data

```python
# See more information about data
df.info()

```

---

- The df.info() function in pandas provides a concise summary of a DataFrame, including the number of non-null entries, data types of each column, and memory usage. This function is particularly useful for getting a quick overview of your dataset.

- As we can see our data is very clean

```python
# How many Nan in data
df.isnull().sum()

```

---

StudentID            0
Age                  0
Gender               0
Ethnicity            0
ParentalEducation    0
StudyTimeWeekly      0
Absences             0
Tutoring             0
ParentalSupport      0
Extracurricular      0
Sports               0
Music                0
Volunteering         0
GPA                  0
GradeClass           0
dtype: int64

---

- The df.isnull().sum() function in pandas is used to detect missing values (null values) in a DataFrame and return the count of null values in each column. This function is very useful for quickly assessing the completeness of your dataset and identifying columns with missing data.

---

```python
# How many Nan in data
df.isnull().sum()

```

---

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StudentID</th>
      <th>Age</th>
      <th>Gender</th>
      <th>Ethnicity</th>
      <th>ParentalEducation</th>
      <th>StudyTimeWeekly</th>
      <th>Absences</th>
      <th>Tutoring</th>
      <th>ParentalSupport</th>
      <th>Extracurricular</th>
      <th>Sports</th>
      <th>Music</th>
      <th>Volunteering</th>
      <th>GPA</th>
      <th>GradeClass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
      <td>2392.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2196.500000</td>
      <td>16.468645</td>
      <td>0.510870</td>
      <td>0.877508</td>
      <td>1.746237</td>
      <td>9.771992</td>
      <td>14.541388</td>
      <td>0.301421</td>
      <td>2.122074</td>
      <td>0.383361</td>
      <td>0.303512</td>
      <td>0.196906</td>
      <td>0.157191</td>
      <td>1.906186</td>
      <td>2.983696</td>
    </tr>
    <tr>
      <th>std</th>
      <td>690.655244</td>
      <td>1.123798</td>
      <td>0.499986</td>
      <td>1.028476</td>
      <td>1.000411</td>
      <td>5.652774</td>
      <td>8.467417</td>
      <td>0.458971</td>
      <td>1.122813</td>
      <td>0.486307</td>
      <td>0.459870</td>
      <td>0.397744</td>
      <td>0.364057</td>
      <td>0.915156</td>
      <td>1.233908</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1001.000000</td>
      <td>15.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.001057</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1598.750000</td>
      <td>15.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>5.043079</td>
      <td>7.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.174803</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2196.500000</td>
      <td>16.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>9.705363</td>
      <td>15.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.893393</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2794.250000</td>
      <td>17.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>14.408410</td>
      <td>22.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.622216</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3392.000000</td>
      <td>18.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>4.000000</td>
      <td>19.978094</td>
      <td>29.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
    </tr>
  </tbody>
</table>
</div>

---

```python
# quantity of unique values in columns
df.nunique()

```

---

StudentID            2392
Age                     4
Gender                  2
Ethnicity               4
ParentalEducation       5
StudyTimeWeekly      2392
Absences               30
Tutoring                2
ParentalSupport         5
Extracurricular         2
Sports                  2
Music                   2
Volunteering            2
GPA                  2371
GradeClass              5
dtype: int64

---

- df.nunique(): Returns a Series with the number of unique values in each column.

---

## Data Visualization

```python
# list of categorical columns where quantity of unique values <= 5 
categ_cols = ['Age','Gender','Ethnicity','ParentalEducation','Tutoring','Extracurricular','ParentalSupport','Sports','Music','Volunteering']

custom_labels = {
    'Ethnicity': ['Caucasian', 'African American', 'Asian', 'Other'],
    'Age': [15, 16, 17, 18],
    'ParentalEducation': ['None', 'High School', 'Some College', 'Bachelor\'s', 'Higher'],
    'Tutoring': ['No', 'Yes'],
    'ParentalSupport': ['No', 'Low', 'Moderate', 'High', 'Very High'],
    'Extracurricular': ['No', 'Yes'],
    'Sports': ['No', 'Yes'],
    'Music': ['No', 'Yes'],
    'Volunteering': ['No', 'Yes'],
    'Gender': ['Male', 'Female']
}

for col in categ_cols:
    plt.figure(figsize=(7, 4))
    sns.countplot(data=df, x=col,palette='deep')
    
    plt.title(f'Countplot of {col}')
    
    labels = custom_labels[col]
    ticks = range(len(labels))
    plt.xticks(ticks=ticks, labels=labels)
    
    plt.tight_layout()
    plt.show()

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a1.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a2.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a3.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a4.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a5.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a6.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a7.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a8.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a9.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/a99.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

## Code Explanation

- Loop Through Categorical Columns: Iterate over each column in categ_cols.

- Create a Figure: Set the size of the figure using plt.figure(figsize=(7, 4)).

- Generate Count Plot: Use Seaborn's countplot to plot the counts of unique values in the column.

- Set Title: Add a title to the plot using plt.title.

- Set Custom Labels for X-Ticks: Customize the x-axis labels using plt.xticks.

- Layout Adjustment: Adjust the layout to ensure everything fits well using plt.tight_layout.

- Display Plot: Show the plot using plt.show().

---

```python
# numerical columns
numeric_cols = ['StudyTimeWeekly','Absences']

for col in numeric_cols:
    plt.figure(figsize=(6, 4))
    sns.histplot(data=df, x=col, kde=True, bins=25)
    plt.title(f'Distribution of {col}')
    plt.show()

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b1.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b2.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

## Explanation

- plt.figure(figsize=(6, 4)): Sets the size of the plot.

- sns.histplot(data=df, x=col, kde=True, bins=25): Creates a histogram for the column with KDE and 25 bins.

- plt.title(f'Distribution of {col}'): Sets the title of the plot.

- plt.show(): Displays the plot.

```python
# How many Nan in data
df.isnull().sum()

```

---

```python
plt.figure(figsize = (7,5))

labels = ['A','B','C','D','F']
ticks = range(len(labels))

sns.countplot(data = df, x = 'GradeClass',palette = 'deep')

plt.xticks(ticks= ticks,labels=labels)
plt.title("GradeClass Distribution Bar Plot")

plt.show()

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b3.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

```python
plt.figure(figsize = (7,5))

labels = ['A','B','C','D','F']
ticks = range(len(labels))

sns.countplot(data = df, x = 'GradeClass',palette = 'deep')

plt.xticks(ticks= ticks,labels=labels)
plt.title("GradeClass Distribution Bar Plot")

plt.show()

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b4.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

## Explanation

- Sample DataFrame: A sample DataFrame df is created with a GradeClass column containing grades.

- Labels and Ticks: Define the labels and corresponding ticks for the x-axis.

- Create the Figure: Use plt.figure(figsize=(7, 5)) to set the size of the plot.

- Count Plot: Use Seabornâ€™s countplot to plot the counts of each GradeClass.

- Set x-ticks: Use plt.xticks(ticks=ticks, labels=labels) to set the custom labels for the x-axis.

- Title: Set the title of the plot with plt.title.

- Show Plot: Display the plot using plt.show().

---

```python
plt.figure(figsize = (7,5))

colors = sns.color_palette('deep')[ 0:5 ]

plt.pie(df['GradeClass'].value_counts().sort_index(),labels = labels,colors = colors,autopct='%.0f%%')
plt.title("GradeClass Distribution Pie Chart")

plt.show() 

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b5.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

## Explanation

- df['GradeClass'].value_counts().sort_index(): Counts the occurrences of each grade class and sorts them by their index.

- sns.color_palette('deep')[0:5]: Generates a palette of colors from Seaborn's deep palette for the pie slices.

- plt.pie(): Creates the pie chart with specified labels, colors, and percentage formatting (autopct='%.0f%%').

- plt.title(): Sets the title of the pie chart.

---

```python
plt.figure(figsize=(12,10), dpi= 80)
sns.heatmap(df.corr(), xticklabels=df.corr().columns, yticklabels=df.corr().columns, cmap='RdYlGn', center=0, annot=True)

plt.title('Correlogram of mtcars', fontsize=22)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b7.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

## Code Explanation

- Import Libraries: Ensure you have imported necessary libraries (matplotlib.pyplot and seaborn).

- Set Figure Size and DPI: Use plt.figure(figsize=(12, 10), dpi=80) to set the size of the figure and the dots per inch (resolution).

- Create Heatmap: Use sns.heatmap() to plot the correlation matrix (df.corr()). Parameters include:

- xticklabels and yticklabels: Sets the labels for the x-axis and y-axis based on column names.

- cmap='RdYlGn': Specifies the color map (Red-Yellow-Green).

- center=0: Sets the center of the color map at 0.

- annot=True: Displays the correlation coefficients on the heatmap.

- Set Title and Axis Labels: Use plt.title() to set the title of the plot and plt.xticks() / plt.yticks() to adjust the font size of tick labels.

- Display Plot: Use plt.show() to display the heatmap.

---

```python
plt.figure(figsize=(10,8), dpi= 80)
sns.lineplot(df,x = 'Absences',y = 'GradeClass')
plt.show()

```

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b9.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

# **Data Modeling**

```python
y = df['GradeClass']
X = df.drop('GradeClass',axis = 1)

```

---

```python
print(X.shape,y.shape)

```

---

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# scale data
scaler = StandardScaler()
scaler.fit(X)
X_scaled = scaler.transform(X)

# split our data to train ans test
X_train,X_test,y_train,y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=0)

```

---

```python
from sklearn.metrics import accuracy_score
# LogisticRegression
from sklearn.linear_model import LogisticRegression

reg = LogisticRegression()
reg.fit(X_train,y_train)

y_pred = reg.predict(X_test)
y_pred = pd.Series(y_pred)

logist_clf_score = accuracy_score(y_test, y_pred)
print(f"LogisticRegression: {logist_clf_score}") # LogisticRegression: 0.7089136490250696

```

> LogisticRegression: 0.7089136490250696

---

```python
# KNN
from sklearn.neighbors import KNeighborsClassifier

mx = 0 # max accuracy
mx_n = 0 # max_accuracy n_neighbours

n_arr = [] # list for n_neight
n_score = [] # list for accuracies

for n_neigh in range(1,50):
    
    neigh = KNeighborsClassifier(n_neighbors=n_neigh)
    neigh.fit(X_train, y_train)
    
    y_pred = pd.Series(neigh.predict(X_test))
    
    n_acc = accuracy_score(y_test, y_pred)
    
    n_arr.append(n_neigh)
    n_score.append(n_acc)
    
    if n_acc > mx:
        mx = n_acc
        mx_n = n_neigh
        
print("=== KNN ===")
print(f"Max accuracy: {mx}") # Max accuracy: 0.6114206128133705
print(f"Best param: {mx_n}") # Best param: 23
print("===========")
sns.lineplot(x = n_arr,y = n_score)
6

```

>=== KNN ===
>Max accuracy: 0.6114206128133705
>Best param: 23
>===========

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b99.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---

```python
# DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV  

param_grid = [{
    'criterion': ['gini','entropy','log_loss'],
    'max_depth': [1,2,3,5,7,9,11],
    'min_samples_split': [2,3,5,6,7,9]
}]

des_tree = DecisionTreeClassifier()

clf = GridSearchCV(des_tree, param_grid)
clf.fit(X_train,y_train)

y_pred = pd.Series(clf.predict(X_test))

des_tree_acc = accuracy_score(y_test, y_pred)

print(f"DecisionTreeClassifier: {des_tree_acc}") # DecisionTreeClassifier: 0.6657381615598886
print(clf.best_params_) # 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2

```

> DecisionTreeClassifier: 0.6657381615598886
> {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}

---

```python
from sklearn.ensemble import RandomForestClassifier

rand_forst = RandomForestClassifier(n_estimators = 1000,criterion = 'log_loss',max_depth = 11,min_samples_split = 5,min_samples_leaf=3)
rand_forst.fit(X_train,y_train)

y_pred = pd.Series(rand_forst.predict(X_test))
rand_forst_acc = accuracy_score(y_test, y_pred)

print(f"RandomForestClassifier: {rand_forst_acc}")2

```

> RandomForestClassifier: 0.6991643454038997

---

```python
models = ['LogisticRegression','RandomForestClassifier','DecisionTreeClassifier','KNN']
models_acc = [0.7089136490250696,0.7005571030640668,0.6657381615598886,0.6114206128133705]

sns.barplot(y = models,x = models_acc)

```

> RandomForestClassifier: 0.6991643454038997

---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/b10.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

---